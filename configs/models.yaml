llm:
  # provider: ollama         # ollama | openai
  # model: llama3            # used if provider=ollama
  provider: openai    # openai | ollama
  model: gpt-4o-mini     # used if provider=openai
  temperature: 0.2

embeddings:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  device: cpu

retrieval:
  # chunking
  chunk_size: 800
  chunk_overlap: 120

  # retrieval
  top_k: 5
  candidate_multiplier: 5
  max_chunks_per_url: 2
  citations_k: 1

  # re-ranking
  use_rerank: true
  reranker_model: cross-encoder/ms-marco-MiniLM-L-6-v2
  reranker_top_n: 30

  # hybrid “grounded vs fallback” gating
  min_hits_for_grounded: 2
  score_threshold: 0.35
  open_domain_fallback: true

  # memory
  mem_enabled: true
  mem_k: 3
